# [Natural Language Processing Specialization](https://www.coursera.org/specializations/natural-language-processing)
<i>A series of 4 courses offered by deeplearning.ai</i>

### Course 1 - [Natural Language Processing with Classification and Vector Spaces](https://www.coursera.org/learn/classification-vector-spaces-in-nlp)

* **Week 1: Logistic Regression**

  * **Lab 1:** [Preprocessing.ipynb](https://github.com/Andrew-Ng-s-number-one-fan/Natural-Language-Processing-Specialization/blob/master/01%20-%20Natural%20Language%20Processing%20with%20Classification%20and%20Vector%20Spaces/C1_W1_N1_Preprocessing.ipynb)
  * **Lab 2:** [Building and Visualizing Word Frequencies.ipynb](https://github.com/Andrew-Ng-s-number-one-fan/Natural-Language-Processing-Specialization/blob/master/01%20-%20Natural%20Language%20Processing%20with%20Classification%20and%20Vector%20Spaces/C1_W1_N2_Building%20and%20Visualizing%20Word%20Frequencies.ipynb)
  * **Lab 3:** [Visualizing Tweets and the Logistic Regression Model.ipynb](https://github.com/Andrew-Ng-s-number-one-fan/Natural-Language-Processing-Specialization/blob/master/01%20-%20Natural%20Language%20Processing%20with%20Classification%20and%20Vector%20Spaces/C1_W1_N3_Visualizing%20Tweets%20and%20the%20Logistic%20Regression%20Model.ipynb)
  * **Assignment:** [Logistic Regression.ipynb](https://github.com/Andrew-Ng-s-number-one-fan/Natural-Language-Processing-Specialization/blob/master/01%20-%20Natural%20Language%20Processing%20with%20Classification%20and%20Vector%20Spaces/C1_W1_Assignment.ipynb)
  
* **Week 2: Naïve Bayes**
  * **Lab:** [Visualizing Likelihoods and Confidence Ellipses.ipynb](https://github.com/Andrew-Ng-s-number-one-fan/Natural-Language-Processing-Specialization/blob/master/01%20-%20Natural%20Language%20Processing%20with%20Classification%20and%20Vector%20Spaces/C1_W2_N1_Visualizing%20Likelihoods%20and%20Confidence%20Ellipses.ipynb)
  * **Assignment:** [Naïve Bayes.ipynb](https://github.com/Andrew-Ng-s-number-one-fan/Natural-Language-Processing-Specialization/blob/master/01%20-%20Natural%20Language%20Processing%20with%20Classification%20and%20Vector%20Spaces/C1_W2_Assignment.ipynb)
  
* **Week 3: Word Embeddings**
  * **Lab 1:** [Linear Algebra in Python with Numpy.ipynb](https://github.com/Andrew-Ng-s-number-one-fan/Natural-Language-Processing-Specialization/blob/master/01%20-%20Natural%20Language%20Processing%20with%20Classification%20and%20Vector%20Spaces/C1_W3_N1_Linear%20Algebra%20in%20Python%20with%20NumPy.ipynb)
  * **Lab 2:** [Manipulating Word Embeddings.ipynb](https://github.com/Andrew-Ng-s-number-one-fan/Natural-Language-Processing-Specialization/blob/master/01%20-%20Natural%20Language%20Processing%20with%20Classification%20and%20Vector%20Spaces/C1_W3_N2_Manipulating%20Word%20Embeddings.ipynb)
  * **Lab 3:** [Another Explanation about PCA.ipynb](https://github.com/Andrew-Ng-s-number-one-fan/Natural-Language-Processing-Specialization/blob/master/01%20-%20Natural%20Language%20Processing%20with%20Classification%20and%20Vector%20Spaces/C1_W3_N3_Another%20Explanation%20about%20PCA.ipynb)
  * **Assignment:** Word Embeddings
  
* **Week 4: Word Translation**
  * **Lab 1:** [Rotation Matrices in R2.ipynb]()
  * **Lab 2:** [Hash Tables.ipynb]()
  * **Assignment:** Word Translation

<hr>

### Course 2 - [Natural Language Processing with Probabilistic Models](https://www.coursera.org/learn/probabilistic-models-in-nlp)

* **Week 1: Autocorrect**

  * **Lab 1:** [Building the Vocabulary.ipynb]()
  * **Lab 2:** [Candidates from Edits.ipynb]()
  * **Assignment:** Autocorrect
  
* **Week 2: Part of Speech Tagging**

  * **Lab 1:** [Working with Text Data 1.ipynb]()
  * **Lab 2:** [Working with Text Data 2.ipynb]()
  * **Assignment:** Part of Speech Tagging
  
* **Week 3: Autocomplete**

  * **Lab 1:** [Corpus Preprocessing for N-grams.ipynb]()
  * **Lab 2:** [Building the Language Model.ipynb]()
  * **Lab 3:** [Language Model Generalization.ipynb]()
  * **Assignment:** Autocomplete
  
* **Week 4: Word Embeddings**

  * **Lab 1:** [Data Preparation.ipynb]()
  * **Lab 2:** [Intro to CBOW Model.ipynb]()
  * **Lab 3:** [Training the CBOW Model.ipynb]()
  * **Lab 4:** [Word Embeddings.ipynb]()
  * **Lab 5:** [Word embeddings Step by Step.ipynb]()
  * **Assignment:** Word Embeddings

<hr>

### Course 3 - [Natural Language Processing with Sequence Models](https://www.coursera.org/learn/sequence-models-in-nlp)

<hr>

### Course 4 - [Natural Language Processing with Attention Models](https://www.coursera.org/learn/attention-models-in-nlp)
